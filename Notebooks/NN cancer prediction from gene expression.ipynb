{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41f09e2d-ffeb-45b4-ab55-d2eae8990e4b",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d955a60-437d-47cc-a3ab-d5583fc0bb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "156a8b30-ca67-4899-aeae-f1a81a2feab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d4b80253-8fcd-47a0-bf28-6901958aa103",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa981fcf-ba25-441d-8e8c-83c4cc811e0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/anaconda3/lib/python3.12/site-packages (2.16.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (24.12.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.32.2)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.68.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "092f9046-835e-473e-8e9b-234178141dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(location):\n",
    "    with open(os.path.expanduser(location), \"r\") as file:\n",
    "        return pd.read_csv(location)\n",
    "\n",
    "cancer_df = read_file(\"Desktop/cancer-ML-practice/Data 23/cancer_gene_expression.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a6b7346-837d-4a86-84fa-b6978d859f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(801, 8001)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(cancer_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ebaea7f-99f2-4a49-85d8-b3b3178511fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_1</th>\n",
       "      <th>gene_2</th>\n",
       "      <th>gene_3</th>\n",
       "      <th>gene_4</th>\n",
       "      <th>gene_5</th>\n",
       "      <th>gene_6</th>\n",
       "      <th>gene_7</th>\n",
       "      <th>gene_8</th>\n",
       "      <th>gene_9</th>\n",
       "      <th>gene_10</th>\n",
       "      <th>...</th>\n",
       "      <th>gene_7992</th>\n",
       "      <th>gene_7993</th>\n",
       "      <th>gene_7994</th>\n",
       "      <th>gene_7995</th>\n",
       "      <th>gene_7996</th>\n",
       "      <th>gene_7997</th>\n",
       "      <th>gene_7998</th>\n",
       "      <th>gene_7999</th>\n",
       "      <th>gene_8000</th>\n",
       "      <th>Cancer_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.088413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.550605</td>\n",
       "      <td>2.815760</td>\n",
       "      <td>...</td>\n",
       "      <td>11.558803</td>\n",
       "      <td>8.881802</td>\n",
       "      <td>6.014840</td>\n",
       "      <td>6.643534</td>\n",
       "      <td>11.740624</td>\n",
       "      <td>7.065012</td>\n",
       "      <td>9.932659</td>\n",
       "      <td>6.928584</td>\n",
       "      <td>2.088413</td>\n",
       "      <td>KIRC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.205955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.425244</td>\n",
       "      <td>2.354396</td>\n",
       "      <td>...</td>\n",
       "      <td>11.062829</td>\n",
       "      <td>9.032864</td>\n",
       "      <td>5.054193</td>\n",
       "      <td>6.432320</td>\n",
       "      <td>12.104985</td>\n",
       "      <td>7.300746</td>\n",
       "      <td>9.872796</td>\n",
       "      <td>5.039231</td>\n",
       "      <td>2.448002</td>\n",
       "      <td>KIRC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.746646</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.639417</td>\n",
       "      <td>1.657091</td>\n",
       "      <td>...</td>\n",
       "      <td>12.497640</td>\n",
       "      <td>7.198160</td>\n",
       "      <td>0.943434</td>\n",
       "      <td>7.371690</td>\n",
       "      <td>11.202356</td>\n",
       "      <td>8.426588</td>\n",
       "      <td>11.176890</td>\n",
       "      <td>3.119738</td>\n",
       "      <td>4.433988</td>\n",
       "      <td>BRCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.173191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.527371</td>\n",
       "      <td>2.732899</td>\n",
       "      <td>...</td>\n",
       "      <td>11.261713</td>\n",
       "      <td>8.725676</td>\n",
       "      <td>6.300418</td>\n",
       "      <td>6.036451</td>\n",
       "      <td>11.732303</td>\n",
       "      <td>7.559469</td>\n",
       "      <td>9.596453</td>\n",
       "      <td>2.863046</td>\n",
       "      <td>3.380342</td>\n",
       "      <td>KIRC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.366532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.388355</td>\n",
       "      <td>...</td>\n",
       "      <td>12.241965</td>\n",
       "      <td>7.685204</td>\n",
       "      <td>5.142948</td>\n",
       "      <td>6.355788</td>\n",
       "      <td>11.493950</td>\n",
       "      <td>8.139444</td>\n",
       "      <td>10.189256</td>\n",
       "      <td>6.544487</td>\n",
       "      <td>0.839395</td>\n",
       "      <td>COAD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gene_1  gene_2  gene_3    gene_4  gene_5  gene_6  gene_7  gene_8    gene_9  \\\n",
       "0     0.0     0.0     0.0  2.088413     0.0     0.0     0.0     0.0  0.550605   \n",
       "1     0.0     0.0     0.0  3.205955     0.0     0.0     0.0     0.0  0.425244   \n",
       "2     0.0     0.0     0.0  4.746646     0.0     0.0     0.0     0.0  2.639417   \n",
       "3     0.0     0.0     0.0  1.173191     0.0     0.0     0.0     0.0  1.527371   \n",
       "4     0.0     0.0     0.0  1.366532     0.0     0.0     0.0     0.0  0.000000   \n",
       "\n",
       "    gene_10  ...  gene_7992  gene_7993  gene_7994  gene_7995  gene_7996  \\\n",
       "0  2.815760  ...  11.558803   8.881802   6.014840   6.643534  11.740624   \n",
       "1  2.354396  ...  11.062829   9.032864   5.054193   6.432320  12.104985   \n",
       "2  1.657091  ...  12.497640   7.198160   0.943434   7.371690  11.202356   \n",
       "3  2.732899  ...  11.261713   8.725676   6.300418   6.036451  11.732303   \n",
       "4  3.388355  ...  12.241965   7.685204   5.142948   6.355788  11.493950   \n",
       "\n",
       "   gene_7997  gene_7998  gene_7999  gene_8000  Cancer_Type  \n",
       "0   7.065012   9.932659   6.928584   2.088413         KIRC  \n",
       "1   7.300746   9.872796   5.039231   2.448002         KIRC  \n",
       "2   8.426588  11.176890   3.119738   4.433988         BRCA  \n",
       "3   7.559469   9.596453   2.863046   3.380342         KIRC  \n",
       "4   8.139444  10.189256   6.544487   0.839395         COAD  \n",
       "\n",
       "[5 rows x 8001 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_df.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d33126d9-7f72-4ad0-bb7b-55206904dd9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_1</th>\n",
       "      <th>gene_2</th>\n",
       "      <th>gene_3</th>\n",
       "      <th>gene_4</th>\n",
       "      <th>gene_5</th>\n",
       "      <th>gene_6</th>\n",
       "      <th>gene_7</th>\n",
       "      <th>gene_8</th>\n",
       "      <th>gene_9</th>\n",
       "      <th>gene_10</th>\n",
       "      <th>...</th>\n",
       "      <th>gene_7992</th>\n",
       "      <th>gene_7993</th>\n",
       "      <th>gene_7994</th>\n",
       "      <th>gene_7995</th>\n",
       "      <th>gene_7996</th>\n",
       "      <th>gene_7997</th>\n",
       "      <th>gene_7998</th>\n",
       "      <th>gene_7999</th>\n",
       "      <th>gene_8000</th>\n",
       "      <th>Cancer_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.088413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.550605</td>\n",
       "      <td>2.815760</td>\n",
       "      <td>...</td>\n",
       "      <td>11.558803</td>\n",
       "      <td>8.881802</td>\n",
       "      <td>6.014840</td>\n",
       "      <td>6.643534</td>\n",
       "      <td>11.740624</td>\n",
       "      <td>7.065012</td>\n",
       "      <td>9.932659</td>\n",
       "      <td>6.928584</td>\n",
       "      <td>2.088413</td>\n",
       "      <td>KIRC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.205955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.425244</td>\n",
       "      <td>2.354396</td>\n",
       "      <td>...</td>\n",
       "      <td>11.062829</td>\n",
       "      <td>9.032864</td>\n",
       "      <td>5.054193</td>\n",
       "      <td>6.432320</td>\n",
       "      <td>12.104985</td>\n",
       "      <td>7.300746</td>\n",
       "      <td>9.872796</td>\n",
       "      <td>5.039231</td>\n",
       "      <td>2.448002</td>\n",
       "      <td>KIRC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.746646</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.639417</td>\n",
       "      <td>1.657091</td>\n",
       "      <td>...</td>\n",
       "      <td>12.497640</td>\n",
       "      <td>7.198160</td>\n",
       "      <td>0.943434</td>\n",
       "      <td>7.371690</td>\n",
       "      <td>11.202356</td>\n",
       "      <td>8.426588</td>\n",
       "      <td>11.176890</td>\n",
       "      <td>3.119738</td>\n",
       "      <td>4.433988</td>\n",
       "      <td>BRCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.173191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.527371</td>\n",
       "      <td>2.732899</td>\n",
       "      <td>...</td>\n",
       "      <td>11.261713</td>\n",
       "      <td>8.725676</td>\n",
       "      <td>6.300418</td>\n",
       "      <td>6.036451</td>\n",
       "      <td>11.732303</td>\n",
       "      <td>7.559469</td>\n",
       "      <td>9.596453</td>\n",
       "      <td>2.863046</td>\n",
       "      <td>3.380342</td>\n",
       "      <td>KIRC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.366532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.388355</td>\n",
       "      <td>...</td>\n",
       "      <td>12.241965</td>\n",
       "      <td>7.685204</td>\n",
       "      <td>5.142948</td>\n",
       "      <td>6.355788</td>\n",
       "      <td>11.493950</td>\n",
       "      <td>8.139444</td>\n",
       "      <td>10.189256</td>\n",
       "      <td>6.544487</td>\n",
       "      <td>0.839395</td>\n",
       "      <td>COAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.933384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.683921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.635336</td>\n",
       "      <td>1.252839</td>\n",
       "      <td>...</td>\n",
       "      <td>9.985842</td>\n",
       "      <td>9.469967</td>\n",
       "      <td>4.225275</td>\n",
       "      <td>6.955336</td>\n",
       "      <td>11.722206</td>\n",
       "      <td>7.309940</td>\n",
       "      <td>10.986119</td>\n",
       "      <td>6.396848</td>\n",
       "      <td>1.252839</td>\n",
       "      <td>BRCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.772625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.534759</td>\n",
       "      <td>3.761764</td>\n",
       "      <td>...</td>\n",
       "      <td>12.334681</td>\n",
       "      <td>8.157327</td>\n",
       "      <td>1.482797</td>\n",
       "      <td>6.758183</td>\n",
       "      <td>11.403838</td>\n",
       "      <td>9.005347</td>\n",
       "      <td>11.012045</td>\n",
       "      <td>5.386625</td>\n",
       "      <td>1.697640</td>\n",
       "      <td>COAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.408277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.854754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.986520</td>\n",
       "      <td>...</td>\n",
       "      <td>11.671992</td>\n",
       "      <td>8.859616</td>\n",
       "      <td>6.393828</td>\n",
       "      <td>6.427115</td>\n",
       "      <td>11.596586</td>\n",
       "      <td>7.454127</td>\n",
       "      <td>10.718533</td>\n",
       "      <td>5.507417</td>\n",
       "      <td>1.398131</td>\n",
       "      <td>BRCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.639232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.226971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.921322</td>\n",
       "      <td>0.639232</td>\n",
       "      <td>...</td>\n",
       "      <td>12.237087</td>\n",
       "      <td>5.753976</td>\n",
       "      <td>4.192478</td>\n",
       "      <td>6.614875</td>\n",
       "      <td>11.183245</td>\n",
       "      <td>7.544261</td>\n",
       "      <td>10.649382</td>\n",
       "      <td>5.282158</td>\n",
       "      <td>0.639232</td>\n",
       "      <td>BRCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.336912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.926379</td>\n",
       "      <td>1.233090</td>\n",
       "      <td>...</td>\n",
       "      <td>11.086966</td>\n",
       "      <td>8.345086</td>\n",
       "      <td>7.789018</td>\n",
       "      <td>6.472460</td>\n",
       "      <td>11.819836</td>\n",
       "      <td>8.082942</td>\n",
       "      <td>10.397717</td>\n",
       "      <td>7.550000</td>\n",
       "      <td>0.926379</td>\n",
       "      <td>COAD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>801 rows × 8001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gene_1    gene_2  gene_3    gene_4  gene_5  gene_6  gene_7  gene_8  \\\n",
       "0       0.0  0.000000     0.0  2.088413     0.0     0.0     0.0     0.0   \n",
       "1       0.0  0.000000     0.0  3.205955     0.0     0.0     0.0     0.0   \n",
       "2       0.0  0.000000     0.0  4.746646     0.0     0.0     0.0     0.0   \n",
       "3       0.0  0.000000     0.0  1.173191     0.0     0.0     0.0     0.0   \n",
       "4       0.0  0.000000     0.0  1.366532     0.0     0.0     0.0     0.0   \n",
       "..      ...       ...     ...       ...     ...     ...     ...     ...   \n",
       "796     0.0  2.933384     0.0  1.683921     0.0     0.0     0.0     0.0   \n",
       "797     0.0  0.000000     0.0  2.772625     0.0     0.0     0.0     0.0   \n",
       "798     0.0  0.408277     0.0  1.854754     0.0     0.0     0.0     0.0   \n",
       "799     0.0  0.639232     0.0  3.226971     0.0     0.0     0.0     0.0   \n",
       "800     0.0  0.000000     0.0  2.336912     0.0     0.0     0.0     0.0   \n",
       "\n",
       "       gene_9   gene_10  ...  gene_7992  gene_7993  gene_7994  gene_7995  \\\n",
       "0    0.550605  2.815760  ...  11.558803   8.881802   6.014840   6.643534   \n",
       "1    0.425244  2.354396  ...  11.062829   9.032864   5.054193   6.432320   \n",
       "2    2.639417  1.657091  ...  12.497640   7.198160   0.943434   7.371690   \n",
       "3    1.527371  2.732899  ...  11.261713   8.725676   6.300418   6.036451   \n",
       "4    0.000000  3.388355  ...  12.241965   7.685204   5.142948   6.355788   \n",
       "..        ...       ...  ...        ...        ...        ...        ...   \n",
       "796  0.635336  1.252839  ...   9.985842   9.469967   4.225275   6.955336   \n",
       "797  0.534759  3.761764  ...  12.334681   8.157327   1.482797   6.758183   \n",
       "798  0.000000  0.986520  ...  11.671992   8.859616   6.393828   6.427115   \n",
       "799  1.921322  0.639232  ...  12.237087   5.753976   4.192478   6.614875   \n",
       "800  0.926379  1.233090  ...  11.086966   8.345086   7.789018   6.472460   \n",
       "\n",
       "     gene_7996  gene_7997  gene_7998  gene_7999  gene_8000  Cancer_Type  \n",
       "0    11.740624   7.065012   9.932659   6.928584   2.088413         KIRC  \n",
       "1    12.104985   7.300746   9.872796   5.039231   2.448002         KIRC  \n",
       "2    11.202356   8.426588  11.176890   3.119738   4.433988         BRCA  \n",
       "3    11.732303   7.559469   9.596453   2.863046   3.380342         KIRC  \n",
       "4    11.493950   8.139444  10.189256   6.544487   0.839395         COAD  \n",
       "..         ...        ...        ...        ...        ...          ...  \n",
       "796  11.722206   7.309940  10.986119   6.396848   1.252839         BRCA  \n",
       "797  11.403838   9.005347  11.012045   5.386625   1.697640         COAD  \n",
       "798  11.596586   7.454127  10.718533   5.507417   1.398131         BRCA  \n",
       "799  11.183245   7.544261  10.649382   5.282158   0.639232         BRCA  \n",
       "800  11.819836   8.082942  10.397717   7.550000   0.926379         COAD  \n",
       "\n",
       "[801 rows x 8001 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78993586-138c-4af7-a36a-047430241298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    KIRC\n",
       "1    KIRC\n",
       "2    BRCA\n",
       "3    KIRC\n",
       "4    COAD\n",
       "Name: Cancer_Type, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_df[\"Cancer_Type\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6d5ee70-48b3-4be2-9c12-6eb23fe4dc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['gene_1', 'gene_2', 'gene_3'], dtype='object') Cancer_Type\n"
     ]
    }
   ],
   "source": [
    "print(cancer_df.columns[:3], cancer_df.columns[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabf571e-1fac-433a-afe0-27d5e0caf184",
   "metadata": {},
   "source": [
    "Exploration and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9a75cefc-27dd-4dfa-aa5c-adfa1df651c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "datanul = cancer_df.isnull().sum()\n",
    "g = [val for val in datanul if val > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "443f63ef-2395-44df-a989-ac0ecd5c159b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values: []\n"
     ]
    }
   ],
   "source": [
    "print(f\"Columns with missing values: {g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cb3b3c0f-0915-4ff2-85fb-b7f50a5a3e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cancer_Type\n",
      "BRCA    300\n",
      "KIRC    146\n",
      "LUAD    141\n",
      "PRAD    136\n",
      "COAD     78\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check different cancer types\n",
    "print(cancer_df[\"Cancer_Type\"].value_counts()) # classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6a98aa-eacd-4bb3-82f1-8d3e08503624",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a82f756d-02ac-4f7f-975a-ca9314244b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to put data in the appropriate format before modelling\n",
    "# separate features from the class\n",
    "X = cancer_df.iloc[:,0:-1]\n",
    "y = cancer_df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "326257a0-e3f5-4bef-a39d-2d583ad112f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(801, 8000) (801,) (801, 8001)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X), np.shape(y), np.shape(cancer_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fd2f64c6-41ee-4219-b707-0f5d5904b221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode labels -> categorical -> discrete\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y)\n",
    "y = label_encoder.transform(y)\n",
    "labels = label_encoder.classes_\n",
    "classes = np.unique(y)\n",
    "nclasses = np.unique(y).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4a20f9df-e92c-4250-95c5-4a98d8e1431b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BRCA', 'COAD', 'KIRC', 'LUAD', 'PRAD'], dtype=object)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7e6ac536-aa8e-4088-b732-969683732173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4] 5\n"
     ]
    }
   ],
   "source": [
    "print(classes, nclasses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc32e6e-e496-4348-be4e-1a3f0b657cfe",
   "metadata": {},
   "source": [
    "Normalisation -> avoid imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ba5c347a-9f9d-4c6f-9122-48778b19a55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_1</th>\n",
       "      <th>gene_2</th>\n",
       "      <th>gene_3</th>\n",
       "      <th>gene_4</th>\n",
       "      <th>gene_5</th>\n",
       "      <th>gene_6</th>\n",
       "      <th>gene_7</th>\n",
       "      <th>gene_8</th>\n",
       "      <th>gene_9</th>\n",
       "      <th>gene_10</th>\n",
       "      <th>...</th>\n",
       "      <th>gene_7991</th>\n",
       "      <th>gene_7992</th>\n",
       "      <th>gene_7993</th>\n",
       "      <th>gene_7994</th>\n",
       "      <th>gene_7995</th>\n",
       "      <th>gene_7996</th>\n",
       "      <th>gene_7997</th>\n",
       "      <th>gene_7998</th>\n",
       "      <th>gene_7999</th>\n",
       "      <th>gene_8000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.088413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.550605</td>\n",
       "      <td>2.815760</td>\n",
       "      <td>...</td>\n",
       "      <td>6.883022</td>\n",
       "      <td>11.558803</td>\n",
       "      <td>8.881802</td>\n",
       "      <td>6.014840</td>\n",
       "      <td>6.643534</td>\n",
       "      <td>11.740624</td>\n",
       "      <td>7.065012</td>\n",
       "      <td>9.932659</td>\n",
       "      <td>6.928584</td>\n",
       "      <td>2.088413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.205955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.425244</td>\n",
       "      <td>2.354396</td>\n",
       "      <td>...</td>\n",
       "      <td>6.271456</td>\n",
       "      <td>11.062829</td>\n",
       "      <td>9.032864</td>\n",
       "      <td>5.054193</td>\n",
       "      <td>6.432320</td>\n",
       "      <td>12.104985</td>\n",
       "      <td>7.300746</td>\n",
       "      <td>9.872796</td>\n",
       "      <td>5.039231</td>\n",
       "      <td>2.448002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.746646</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.639417</td>\n",
       "      <td>1.657091</td>\n",
       "      <td>...</td>\n",
       "      <td>8.417734</td>\n",
       "      <td>12.497640</td>\n",
       "      <td>7.198160</td>\n",
       "      <td>0.943434</td>\n",
       "      <td>7.371690</td>\n",
       "      <td>11.202356</td>\n",
       "      <td>8.426588</td>\n",
       "      <td>11.176890</td>\n",
       "      <td>3.119738</td>\n",
       "      <td>4.433988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.173191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.527371</td>\n",
       "      <td>2.732899</td>\n",
       "      <td>...</td>\n",
       "      <td>4.767210</td>\n",
       "      <td>11.261713</td>\n",
       "      <td>8.725676</td>\n",
       "      <td>6.300418</td>\n",
       "      <td>6.036451</td>\n",
       "      <td>11.732303</td>\n",
       "      <td>7.559469</td>\n",
       "      <td>9.596453</td>\n",
       "      <td>2.863046</td>\n",
       "      <td>3.380342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.366532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.388355</td>\n",
       "      <td>...</td>\n",
       "      <td>7.594086</td>\n",
       "      <td>12.241965</td>\n",
       "      <td>7.685204</td>\n",
       "      <td>5.142948</td>\n",
       "      <td>6.355788</td>\n",
       "      <td>11.493950</td>\n",
       "      <td>8.139444</td>\n",
       "      <td>10.189256</td>\n",
       "      <td>6.544487</td>\n",
       "      <td>0.839395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.933384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.683921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.635336</td>\n",
       "      <td>1.252839</td>\n",
       "      <td>...</td>\n",
       "      <td>7.609312</td>\n",
       "      <td>9.985842</td>\n",
       "      <td>9.469967</td>\n",
       "      <td>4.225275</td>\n",
       "      <td>6.955336</td>\n",
       "      <td>11.722206</td>\n",
       "      <td>7.309940</td>\n",
       "      <td>10.986119</td>\n",
       "      <td>6.396848</td>\n",
       "      <td>1.252839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.772625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.534759</td>\n",
       "      <td>3.761764</td>\n",
       "      <td>...</td>\n",
       "      <td>6.439361</td>\n",
       "      <td>12.334681</td>\n",
       "      <td>8.157327</td>\n",
       "      <td>1.482797</td>\n",
       "      <td>6.758183</td>\n",
       "      <td>11.403838</td>\n",
       "      <td>9.005347</td>\n",
       "      <td>11.012045</td>\n",
       "      <td>5.386625</td>\n",
       "      <td>1.697640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.408277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.854754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.986520</td>\n",
       "      <td>...</td>\n",
       "      <td>7.344802</td>\n",
       "      <td>11.671992</td>\n",
       "      <td>8.859616</td>\n",
       "      <td>6.393828</td>\n",
       "      <td>6.427115</td>\n",
       "      <td>11.596586</td>\n",
       "      <td>7.454127</td>\n",
       "      <td>10.718533</td>\n",
       "      <td>5.507417</td>\n",
       "      <td>1.398131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.639232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.226971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.921322</td>\n",
       "      <td>0.639232</td>\n",
       "      <td>...</td>\n",
       "      <td>6.799502</td>\n",
       "      <td>12.237087</td>\n",
       "      <td>5.753976</td>\n",
       "      <td>4.192478</td>\n",
       "      <td>6.614875</td>\n",
       "      <td>11.183245</td>\n",
       "      <td>7.544261</td>\n",
       "      <td>10.649382</td>\n",
       "      <td>5.282158</td>\n",
       "      <td>0.639232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.336912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.926379</td>\n",
       "      <td>1.233090</td>\n",
       "      <td>...</td>\n",
       "      <td>7.342892</td>\n",
       "      <td>11.086966</td>\n",
       "      <td>8.345086</td>\n",
       "      <td>7.789018</td>\n",
       "      <td>6.472460</td>\n",
       "      <td>11.819836</td>\n",
       "      <td>8.082942</td>\n",
       "      <td>10.397717</td>\n",
       "      <td>7.550000</td>\n",
       "      <td>0.926379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>801 rows × 8000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gene_1    gene_2  gene_3    gene_4  gene_5  gene_6  gene_7  gene_8  \\\n",
       "0       0.0  0.000000     0.0  2.088413     0.0     0.0     0.0     0.0   \n",
       "1       0.0  0.000000     0.0  3.205955     0.0     0.0     0.0     0.0   \n",
       "2       0.0  0.000000     0.0  4.746646     0.0     0.0     0.0     0.0   \n",
       "3       0.0  0.000000     0.0  1.173191     0.0     0.0     0.0     0.0   \n",
       "4       0.0  0.000000     0.0  1.366532     0.0     0.0     0.0     0.0   \n",
       "..      ...       ...     ...       ...     ...     ...     ...     ...   \n",
       "796     0.0  2.933384     0.0  1.683921     0.0     0.0     0.0     0.0   \n",
       "797     0.0  0.000000     0.0  2.772625     0.0     0.0     0.0     0.0   \n",
       "798     0.0  0.408277     0.0  1.854754     0.0     0.0     0.0     0.0   \n",
       "799     0.0  0.639232     0.0  3.226971     0.0     0.0     0.0     0.0   \n",
       "800     0.0  0.000000     0.0  2.336912     0.0     0.0     0.0     0.0   \n",
       "\n",
       "       gene_9   gene_10  ...  gene_7991  gene_7992  gene_7993  gene_7994  \\\n",
       "0    0.550605  2.815760  ...   6.883022  11.558803   8.881802   6.014840   \n",
       "1    0.425244  2.354396  ...   6.271456  11.062829   9.032864   5.054193   \n",
       "2    2.639417  1.657091  ...   8.417734  12.497640   7.198160   0.943434   \n",
       "3    1.527371  2.732899  ...   4.767210  11.261713   8.725676   6.300418   \n",
       "4    0.000000  3.388355  ...   7.594086  12.241965   7.685204   5.142948   \n",
       "..        ...       ...  ...        ...        ...        ...        ...   \n",
       "796  0.635336  1.252839  ...   7.609312   9.985842   9.469967   4.225275   \n",
       "797  0.534759  3.761764  ...   6.439361  12.334681   8.157327   1.482797   \n",
       "798  0.000000  0.986520  ...   7.344802  11.671992   8.859616   6.393828   \n",
       "799  1.921322  0.639232  ...   6.799502  12.237087   5.753976   4.192478   \n",
       "800  0.926379  1.233090  ...   7.342892  11.086966   8.345086   7.789018   \n",
       "\n",
       "     gene_7995  gene_7996  gene_7997  gene_7998  gene_7999  gene_8000  \n",
       "0     6.643534  11.740624   7.065012   9.932659   6.928584   2.088413  \n",
       "1     6.432320  12.104985   7.300746   9.872796   5.039231   2.448002  \n",
       "2     7.371690  11.202356   8.426588  11.176890   3.119738   4.433988  \n",
       "3     6.036451  11.732303   7.559469   9.596453   2.863046   3.380342  \n",
       "4     6.355788  11.493950   8.139444  10.189256   6.544487   0.839395  \n",
       "..         ...        ...        ...        ...        ...        ...  \n",
       "796   6.955336  11.722206   7.309940  10.986119   6.396848   1.252839  \n",
       "797   6.758183  11.403838   9.005347  11.012045   5.386625   1.697640  \n",
       "798   6.427115  11.596586   7.454127  10.718533   5.507417   1.398131  \n",
       "799   6.614875  11.183245   7.544261  10.649382   5.282158   0.639232  \n",
       "800   6.472460  11.819836   8.082942  10.397717   7.550000   0.926379  \n",
       "\n",
       "[801 rows x 8000 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "41cfbf02-5669-41d3-92cb-a8dd22e33f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale between 0-1\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "17bdcd1c-4341-481b-a01e-37d9edf8fc2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.25878855, 0.58811962,\n",
       "        0.2144499 ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.2444709 , 0.40934134,\n",
       "        0.25137454],\n",
       "       [0.        , 0.        , 0.        , ..., 0.556377  , 0.22771114,\n",
       "        0.4553066 ],\n",
       "       ...,\n",
       "       [0.        , 0.06209534, 0.        , ..., 0.44674961, 0.45364308,\n",
       "        0.14356794],\n",
       "       [0.        , 0.09722157, 0.        , ..., 0.43021046, 0.43232813,\n",
       "        0.06563993],\n",
       "       [0.        , 0.        , 0.        , ..., 0.37001869, 0.6469206 ,\n",
       "        0.09512577]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X # scaled up between 0 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e980589f-7018-4b39-aa11-8370fb8867ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 0, 2, 1, 3, 2, 3, 0, 1, 4, 0, 4, 4, 2, 4, 2, 3, 3, 4, 0, 1,\n",
       "       0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 1, 2, 4, 0, 0, 0, 4, 0, 0, 1, 0,\n",
       "       3, 2, 1, 1, 2, 0, 4, 1, 0, 3, 3, 0, 3, 0, 0, 4, 3, 4, 0, 4, 3, 0,\n",
       "       1, 2, 2, 0, 1, 1, 0, 4, 2, 0, 4, 3, 1, 2, 2, 3, 2, 0, 0, 0, 4, 3,\n",
       "       0, 3, 4, 2, 0, 0, 0, 2, 4, 2, 0, 4, 3, 3, 2, 0, 0, 4, 0, 0, 0, 0,\n",
       "       0, 2, 3, 2, 0, 0, 0, 2, 0, 1, 2, 1, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 3, 0, 0, 2, 0, 3, 0, 1, 4, 1, 3, 1, 3, 0, 1, 0, 0, 0,\n",
       "       2, 1, 1, 3, 3, 4, 3, 0, 3, 2, 0, 2, 0, 3, 0, 3, 2, 2, 3, 0, 0, 0,\n",
       "       3, 2, 1, 3, 0, 0, 3, 0, 4, 4, 3, 1, 0, 0, 0, 4, 1, 0, 4, 0, 4, 1,\n",
       "       0, 4, 2, 4, 4, 0, 3, 0, 3, 0, 0, 2, 2, 3, 2, 3, 4, 0, 2, 3, 3, 1,\n",
       "       3, 0, 4, 3, 0, 1, 3, 2, 4, 0, 0, 4, 3, 2, 4, 0, 4, 2, 0, 2, 3, 0,\n",
       "       3, 0, 2, 4, 0, 2, 4, 0, 0, 4, 3, 3, 0, 3, 0, 2, 0, 0, 0, 0, 4, 2,\n",
       "       2, 4, 0, 3, 0, 0, 0, 4, 3, 0, 0, 2, 3, 2, 3, 4, 3, 1, 0, 0, 3, 2,\n",
       "       0, 1, 0, 4, 3, 1, 3, 1, 2, 3, 2, 1, 0, 0, 3, 4, 0, 0, 0, 0, 2, 3,\n",
       "       2, 4, 1, 3, 2, 0, 3, 4, 4, 0, 2, 4, 0, 2, 0, 0, 0, 2, 4, 0, 2, 0,\n",
       "       0, 2, 4, 4, 0, 3, 3, 0, 3, 3, 0, 1, 0, 3, 2, 4, 1, 0, 4, 0, 3, 0,\n",
       "       3, 0, 2, 0, 4, 0, 4, 1, 2, 3, 0, 4, 4, 4, 1, 0, 2, 0, 0, 0, 3, 2,\n",
       "       1, 2, 0, 4, 3, 2, 2, 4, 1, 0, 1, 0, 0, 4, 0, 0, 4, 2, 2, 3, 0, 2,\n",
       "       3, 0, 3, 2, 3, 0, 0, 4, 0, 2, 2, 3, 2, 0, 1, 0, 0, 4, 0, 2, 0, 0,\n",
       "       2, 0, 0, 2, 4, 0, 1, 2, 0, 2, 1, 0, 3, 0, 2, 0, 2, 2, 1, 3, 0, 3,\n",
       "       4, 2, 0, 4, 0, 3, 0, 0, 1, 2, 0, 2, 4, 2, 0, 0, 0, 0, 2, 2, 3, 0,\n",
       "       4, 3, 4, 4, 4, 4, 2, 0, 3, 4, 3, 0, 0, 4, 3, 0, 0, 0, 3, 3, 4, 4,\n",
       "       4, 0, 3, 1, 0, 4, 1, 0, 2, 2, 0, 4, 0, 0, 0, 0, 0, 3, 1, 0, 3, 2,\n",
       "       2, 1, 0, 0, 4, 3, 0, 4, 1, 1, 4, 2, 2, 3, 3, 0, 0, 0, 2, 2, 4, 2,\n",
       "       0, 0, 2, 3, 3, 4, 2, 4, 4, 1, 2, 4, 0, 3, 0, 0, 0, 4, 0, 0, 0, 0,\n",
       "       0, 0, 4, 4, 1, 4, 4, 4, 2, 2, 2, 0, 0, 1, 3, 0, 1, 3, 2, 3, 3, 0,\n",
       "       4, 3, 0, 3, 2, 0, 3, 2, 0, 0, 2, 2, 0, 1, 0, 3, 2, 3, 0, 0, 3, 2,\n",
       "       1, 4, 0, 4, 2, 2, 0, 1, 2, 0, 2, 4, 0, 0, 4, 4, 0, 3, 3, 0, 3, 0,\n",
       "       3, 0, 4, 0, 2, 0, 1, 4, 1, 2, 4, 3, 2, 4, 0, 1, 0, 3, 0, 1, 0, 0,\n",
       "       0, 0, 4, 1, 0, 2, 0, 3, 4, 1, 4, 3, 0, 3, 1, 1, 2, 0, 2, 3, 3, 3,\n",
       "       0, 0, 1, 4, 4, 2, 0, 3, 2, 0, 0, 0, 2, 0, 0, 0, 3, 4, 0, 0, 2, 3,\n",
       "       1, 3, 2, 3, 0, 0, 4, 0, 4, 1, 0, 0, 0, 1, 3, 0, 2, 3, 4, 0, 0, 4,\n",
       "       2, 1, 0, 4, 4, 0, 0, 0, 4, 1, 2, 3, 0, 2, 3, 0, 0, 3, 0, 2, 0, 4,\n",
       "       1, 2, 2, 0, 2, 4, 4, 4, 0, 0, 4, 3, 3, 4, 3, 3, 0, 4, 0, 1, 4, 3,\n",
       "       2, 0, 2, 0, 4, 2, 4, 0, 4, 2, 0, 4, 4, 0, 3, 2, 4, 2, 0, 3, 2, 3,\n",
       "       0, 3, 0, 2, 4, 2, 3, 1, 3, 4, 0, 3, 4, 0, 3, 3, 0, 0, 0, 4, 0, 2,\n",
       "       4, 4, 0, 0, 0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e5248f-4d59-47d2-9631-9fbd4d6e1d5e",
   "metadata": {},
   "source": [
    "Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "71c70425-2d30-4533-b0da-3f9d7f5dc535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into test and training sets and validation\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "# split training set into training and validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e4b6af6d-9cd1-421b-ab72-b2a275d5e362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 8000) (512,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train), np.shape(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c50ec7b0-ba4e-4d28-96d7-4f2dfa3bd796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(161, 8000) (161,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_test), np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6917a407-9b9d-417f-a7b1-091f21824df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 8000) (128,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_val), np.shape(y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd291b1-b0b9-4b81-afa9-c795ca3aea8e",
   "metadata": {},
   "source": [
    "Build NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "38a6383e-c38d-4402-b342-7e665b628035",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() # 3-4 layers\n",
    "\n",
    "# input layer \n",
    "model.add(Input(shape=(X_train.shape[1],)))\n",
    "\n",
    "# hidden layer 1\n",
    "model.add(Dense(40, activation = \"relu\"))\n",
    "\n",
    "# hidden layer 2\n",
    "model.add(Dense(20, activation=\"relu\"))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(nclasses, activation = \"softmax\"))\n",
    "\n",
    "# define optimiser and learning rate\n",
    "opt_adam = keras.optimizers.Adam(learning_rate = 0.001)\n",
    "model.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(), optimizer = opt_adam, metrics = [keras.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ed6dcb92-5158-4f0b-8b93-89684656b7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 1.6633 - sparse_categorical_accuracy: 0.2715 - val_loss: 1.2484 - val_sparse_categorical_accuracy: 0.4141\n",
      "Epoch 2/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2189 - sparse_categorical_accuracy: 0.5534 - val_loss: 0.9561 - val_sparse_categorical_accuracy: 0.6250\n",
      "Epoch 3/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8543 - sparse_categorical_accuracy: 0.7279 - val_loss: 0.7122 - val_sparse_categorical_accuracy: 0.7578\n",
      "Epoch 4/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5706 - sparse_categorical_accuracy: 0.9335 - val_loss: 0.4709 - val_sparse_categorical_accuracy: 0.9609\n",
      "Epoch 5/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3797 - sparse_categorical_accuracy: 0.9821 - val_loss: 0.3417 - val_sparse_categorical_accuracy: 0.9844\n",
      "Epoch 6/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2711 - sparse_categorical_accuracy: 0.9874 - val_loss: 0.2436 - val_sparse_categorical_accuracy: 0.9844\n",
      "Epoch 7/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1718 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.1876 - val_sparse_categorical_accuracy: 0.9844\n",
      "Epoch 8/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1355 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.1467 - val_sparse_categorical_accuracy: 0.9844\n",
      "Epoch 9/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0996 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.1201 - val_sparse_categorical_accuracy: 0.9844\n",
      "Epoch 10/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0756 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0932 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0567 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0822 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0445 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0725 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 13/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0373 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0614 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 14/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0321 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0545 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 15/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0266 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0485 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 16/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0232 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0446 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 17/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0186 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0439 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 18/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0181 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0380 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 19/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0151 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0355 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 20/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0141 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0315 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 21/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0125 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0293 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 22/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0113 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0306 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 23/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0089 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0264 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 24/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0093 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0270 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 25/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0080 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0242 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 26/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0072 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0247 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 27/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0071 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0222 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 28/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0065 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0226 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 29/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0058 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0212 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 30/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0057 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0211 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 31/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0052 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0184 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 32/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0045 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0203 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 33/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0044 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0186 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 34/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0039 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0181 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 35/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0042 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0182 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 36/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0036 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0179 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 37/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0034 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0167 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 38/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0031 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0164 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 39/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0031 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0158 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 40/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0030 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0157 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 41/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0027 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0156 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 42/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0024 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0149 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 43/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0024 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0144 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 44/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0023 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0144 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 45/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0021 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0138 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 46/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0020 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0140 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 47/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0019 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0130 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 48/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0019 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0132 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 49/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0018 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0131 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 50/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0017 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0127 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 51/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0117 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 52/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0015 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0125 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 53/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0016 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0114 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 54/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0014 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0120 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 55/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0113 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 56/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0014 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0108 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 57/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0117 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0107 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 59/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0106 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 60/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0110 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0105 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 62/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0102 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0010 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0105 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.2597e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0098 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.5362e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0103 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.8866e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0099 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.0853e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0097 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.6980e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0099 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.4498e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0093 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.3090e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0091 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.3091e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0099 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.3796e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0091 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.4452e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0092 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.1449e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0091 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.1743e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0086 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.7674e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0091 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.6272e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0085 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.8643e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0086 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.5318e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0089 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.1439e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0081 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.4617e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0085 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.6247e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0085 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.3871e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0080 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.3293e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0083 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.0112e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0082 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.9457e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0076 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.7292e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0081 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.3929e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0076 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.9415e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0081 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.8338e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0074 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.5928e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0072 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.2394e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0080 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.2437e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0076 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.4194e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0075 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.0286e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0072 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.1144e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0074 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.5010e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0076 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.2427e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0070 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.6661e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0071 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.6052e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0068 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.3476e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0073 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.5199e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0071 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.4374e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0065 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.3989e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0071 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.2207e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0066 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.1963e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0070 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.0879e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0067 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.1554e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0067 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.1595e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0065 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.7684e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0067 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.0260e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0065 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.7679e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0066 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.7679e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0062 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.5566e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0062 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.5687e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0065 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.6538e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0063 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.6012e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0060 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.5149e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0063 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.4384e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0063 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.2339e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0061 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.2635e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0063 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.2865e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0060 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.2692e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0061 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.2247e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0060 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.1533e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0058 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.0543e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0060 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.2423e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0061 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.9442e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0058 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.0101e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0058 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.0386e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0058 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.0332e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0059 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7663e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0055 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.9142e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0058 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.8333e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0057 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7139e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0057 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.8136e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0054 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.8243e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0057 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.8442e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0055 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6896e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0057 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.7734e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0055 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7887e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0052 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6071e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0054 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6399e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0054 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5211e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0054 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4754e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0055 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5813e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0052 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5379e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0051 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5261e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0053 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5075e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0053 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4232e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0050 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3873e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0053 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3761e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0053 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3930e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0050 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3109e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0051 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2721e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0050 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3650e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0050 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3369e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0049 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1976e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0051 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2928e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0050 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3052e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0049 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3146e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0049 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2158e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0051 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2221e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0049 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1297e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0047 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1910e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0048 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1491e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0049 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1468e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0047 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1435e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0047 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1349e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0050 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1475e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0046 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0515e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0046 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0625e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0048 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0285e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0046 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0745e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0047 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.9559e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0046 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.7742e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0046 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0802e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0047 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.5088e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0044 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.7108e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0044 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.8080e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0046 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.5425e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0045 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.3329e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0044 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.6023e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0044 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.9013e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0046 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.6807e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0044 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.7014e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0043 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.5892e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0044 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.5013e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0044 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.5051e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0043 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.1014e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0044 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.5827e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0042 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.8544e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0044 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.9340e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0042 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.5367e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0042 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.6287e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0042 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.0662e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0042 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.7705e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0042 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.6355e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0041 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.8249e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0043 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.7239e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0040 - val_sparse_categorical_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# fit model to training data\n",
    "history = model.fit(X_train, y_train, validation_data = (X_val, y_val), batch_size = 32, epochs = 200, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b6602d59-a340-4e2d-af20-fe3d80fb017a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "accuracy = model.evaluate(X_test, y_test, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "baf54182-5f68-4fe5-aa6e-d3b99239337f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:0 ,actual:0\n",
      "predicted:3 ,actual:3\n",
      "predicted:4 ,actual:4\n",
      "predicted:3 ,actual:3\n",
      "predicted:0 ,actual:0\n",
      "predicted:0 ,actual:0\n",
      "predicted:0 ,actual:0\n",
      "predicted:0 ,actual:0\n",
      "predicted:0 ,actual:0\n",
      "predicted:4 ,actual:4\n",
      "predicted:4 ,actual:4\n",
      "predicted:3 ,actual:3\n",
      "predicted:3 ,actual:3\n",
      "predicted:3 ,actual:3\n",
      "predicted:2 ,actual:2\n",
      "predicted:0 ,actual:0\n",
      "predicted:3 ,actual:3\n",
      "predicted:1 ,actual:1\n",
      "predicted:0 ,actual:0\n",
      "predicted:3 ,actual:3\n"
     ]
    }
   ],
   "source": [
    "# get predictions for the first 20 samples of the test set\n",
    "for index, entry in enumerate(predictions[0:20, :]):\n",
    "    print(\"predicted:%d ,actual:%d\"%(np.argmax(entry), y_test[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f3dedd54-0436-4f63-9d02-302ca5a8b33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarise history for accuracy\n",
    "plt.plot(history.history[\"sparse_categorical_accuracy\"])\n",
    "plt.plot(history.history[\"val_sparse_categorical_accuracy\"])\n",
    "plt.title(\"model performance\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train\", \"val\"], loc = \"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ebc685-f069-4cce-83f7-9b5ca3b3a5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarise history for loss\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.title(\"model loss\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train\", \"val\"], loc = \"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
